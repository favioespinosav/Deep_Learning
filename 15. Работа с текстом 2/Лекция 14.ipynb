{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/seb/.local/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/seb/.local/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/seb/.local/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/seb/.local/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/seb/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/seb/.local/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seb/.local/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nmslib\n",
      "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11<2.6.2 (from nmslib)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: psutil in /home/seb/.local/lib/python3.10/site-packages (from nmslib) (5.9.2)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/seb/.local/lib/python3.10/site-packages (from nmslib) (1.24.2)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13550778 sha256=34ca73a8a96f5b1ae04f813cdf359537d2b5895c4a261d56159b424fdeb3c3a5\n",
      "  Stored in directory: /home/seb/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
      "Successfully built nmslib\n",
      "Installing collected packages: pybind11, nmslib\n",
      "  Attempting uninstall: pybind11\n",
      "    Found existing installation: pybind11 2.10.1\n",
      "    Uninstalling pybind11-2.10.1:\n",
      "      Successfully uninstalled pybind11-2.10.1\n",
      "\u001b[33m  WARNING: The script pybind11-config is installed in '/home/seb/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nmslib-2.1.1 pybind11-2.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install nmslib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример: семантическая близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Позовите оператора поддержки, бот не помог',\n",
    "    'Нужна помощь человека для решения вопроса',\n",
    "    'Мне нужна новая карта',\n",
    "    'Хотел бы выпустить ещё одну карточку',\n",
    "    'So, the robot was useless I need a human expert',\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-xlm-r-multilingual-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0319,  0.3350, -0.0372,  ..., -0.0135, -0.1594,  0.2159],\n",
       "        [ 0.0091,  0.2025,  0.1061,  ...,  0.1398, -0.0556,  0.0987],\n",
       "        [-0.0028, -0.0662,  0.1808,  ..., -0.3124,  0.1364, -0.1686],\n",
       "        [ 0.0397,  0.2135, -0.0526,  ...,  0.0632, -0.2187, -0.0405],\n",
       "        [ 0.1122,  0.4121,  0.1259,  ...,  0.0062, -0.2281, -0.0306]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "****************************************************************\n",
      "*"
     ]
    }
   ],
   "source": [
    "import nmslib\n",
    "\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(sentence_embeddings[: -1], ids=list(range(len(sentence_embeddings[: -1]))))\n",
    "index.createIndex({'post': 2}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, distances = index.knnQuery(sentence_embeddings[-1], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позовите оператора поддержки, бот не помог \t 0.53279954\n",
      "Нужна помощь человека для решения вопроса \t 0.6821636\n",
      "Мне нужна новая карта \t 0.7499061\n",
      "Хотел бы выпустить ещё одну карточку \t 0.9512555\n"
     ]
    }
   ],
   "source": [
    "for i, d in zip(ids, distances):\n",
    "    print(sentences[i], '\\t', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример: генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aecfccc02f4a0c8db028f25babd813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c95b56c8fcb4d9d87bc916423637d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e963dee9248a991c9588d6d335b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa91614f7490429f99f1339dc57f4167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Хочу записатся к врачу, но не знаю с чего начать.  Может кто подскажет? \\n Добрый день!  У меня такая проблема: у моего мужа после операции по удалению аппендицита обнаружили опухоль в правом подреберье (похоже на рак).  Врач прописал курс антибиотиков']\n"
     ]
    }
   ],
   "source": [
    "text = 'Хочу записатся к врачу'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_length=64,\n",
    "    repetition_penalty=5.0,\n",
    "    do_sample=False,\n",
    "    top_k=5,\n",
    "    top_p=0.95,\n",
    "    temperature=1.0,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=4,\n",
    ")\n",
    "print([tokenizer.decode(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Archive:  archive.zip\r\n",
      "  inflating: dataset_test.tsv        \r\n",
      "  inflating: dataset_train.tsv       \r\n",
      "  inflating: labels_description.txt  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "transformer.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/transformer_tutorial.ipynb",
     "timestamp": 1576667026572
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
