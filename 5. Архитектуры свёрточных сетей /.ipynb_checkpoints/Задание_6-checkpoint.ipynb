{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gOlDgFqlxO8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import gc\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRXNWadBd31k"
   },
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose([\n",
    "\n",
    "                                        tv.transforms.Resize((224, 224)),\n",
    "                                        tv.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXa0ncwvgFB3"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('hymenoptera_data/train', transform)\n",
    "test_dataset = datasets.ImageFolder('hymenoptera_data/val', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BO2Vcs7j0gU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_images(images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, image in enumerate(images):\n",
    "      numpy_image = image.numpy()\n",
    "      plt.subplot(5, 5, i+1)\n",
    "      # Transpose the numpy array to match the Matplotlib format\n",
    "      matplotlib_image = numpy_image.transpose(1,2,0)\n",
    "\n",
    "      # Display the image using Matplotlib\n",
    "      plt.imshow(matplotlib_image)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ED5xRhsBkZuQ"
   },
   "outputs": [],
   "source": [
    "sample_images = [train_dataset[i][0] for i in range(5)]\n",
    "show_images(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bETYXRexkdIu"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DKG9D_2lo4d"
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, test_iter,trainer,epochs=10):\n",
    "\n",
    "    l_arr = []\n",
    "    model.to(device)\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      train_l_sum,n,train_acc_sum = 0.0, 0,0.0\n",
    "      for i,(X,y) in enumerate(train_iter):\n",
    "\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        trainer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred,y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_l_sum  += l.item()\n",
    "        train_acc_sum += (y_pred.argmax(axis=1)==y).sum().item()\n",
    "        n += y.shape[0]\n",
    "        torch.cuda.empty_cache()\n",
    "        #if epoch % 2:\n",
    "         # print(f\"\"\"Batch {i} LOSS =  {train_l_sum/n} AUC = {train_acc_sum/n} \"\"\")\n",
    "     # if epoch % 2 :\n",
    "     #   test_acc = AUC(model,test_iter)\n",
    "     #   print(f\"\"\"----------------AUC test = {test_acc}------------------------ \"\"\")\n",
    "        del X\n",
    "        del y\n",
    "      l_arr.append(train_l_sum/n)\n",
    "      gc.collect()\n",
    "    return pd.DataFrame({'epoch':list(range(epochs)),'Loss':l_arr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWF24OOMlsDD"
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCJ00bWKl38S"
   },
   "outputs": [],
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSUyqqvVlxES"
   },
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BXCoSQVmBBI"
   },
   "outputs": [],
   "source": [
    "targets = [train_dataset[i][1] for i in range(len(train_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRai4laFl5Vt"
   },
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=2208, out_features=len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HHdfEKYl7PK"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'target':targets})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6tx3ITrmFZ6"
   },
   "outputs": [],
   "source": [
    "df['count'] = 1\n",
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ey-aPL_cmG9t"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrPLKsLCmKem"
   },
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=2208, out_features=len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38AkoM4YmMO-"
   },
   "outputs": [],
   "source": [
    "\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwJH-xJXmOom"
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzE0XYPJmRBX"
   },
   "outputs": [],
   "source": [
    "res_results = train(model, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnX4QylcmSz1"
   },
   "outputs": [],
   "source": [
    "#vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mLuVaWQmZDg"
   },
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose([\n",
    "      tv.transforms.Grayscale(3),\n",
    "    tv.transforms.Resize((32,32)),\n",
    "    tv.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KROpCcOfmdaz"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('hymenoptera_data/train', transform)\n",
    "test_dataset = datasets.ImageFolder('hymenoptera_data/val', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUVUKFJ0mfyZ"
   },
   "outputs": [],
   "source": [
    "model = tv.models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ3omrdFmg2z"
   },
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=25088, out_features=len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJaBjq46mjDO"
   },
   "outputs": [],
   "source": [
    "\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWkUM_29mkmJ"
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QcX1C6ummFt"
   },
   "outputs": [],
   "source": [
    "vgg_results = train(model, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-ejOJSNmnnG"
   },
   "outputs": [],
   "source": [
    "# Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xhP86V5mq_g"
   },
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((299, 299)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder('hymenoptera_data/train', transform)\n",
    "test_dataset = datasets.ImageFolder('hymenoptera_data/val', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7RnS1-Fm4Fl"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC8Op3KWm4cM"
   },
   "outputs": [],
   "source": [
    "model = tv.models.inception_v3(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fC9w2yXxm7QK"
   },
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(model.fc.in_features, len(targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1tC6iDhm9Jf"
   },
   "outputs": [],
   "source": [
    "\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXqT_5k-m_pe"
   },
   "outputs": [],
   "source": [
    "def train_1(model, train_iter, test_iter,trainer,epochs=10):\n",
    "  l_arr = []\n",
    "  model.to(device)\n",
    "  loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    train_l_sum,n,train_acc_sum = 0.0, 0,0.0\n",
    "    for i,(X,y) in enumerate(train_iter):\n",
    "\n",
    "\n",
    "      X,y = X.to(device),y.to(device)\n",
    "      trainer.zero_grad()\n",
    "      _,y_pred = model(X)\n",
    "      l = loss(y_pred,y)\n",
    "      l.backward()\n",
    "      trainer.step()\n",
    "      train_l_sum  += l.item()\n",
    "      train_acc_sum += (y_pred.argmax(axis=1)==y).sum().item()\n",
    "      n += y.shape[0]\n",
    "      torch.cuda.empty_cache()\n",
    "     # if i % 2:\n",
    "     #   print(f\"\"\"Batch {i} LOSS =  {train_l_sum/n} AUC = {train_acc_sum/n} \"\"\")\n",
    "    #if epoch % 2 :\n",
    "    #  test_acc = AUC(model,test_iter)\n",
    "    #  print(f\"\"\"----------------AUC test = {test_acc}------------------------ \"\"\")\n",
    "\n",
    "    l_arr.append(train_l_sum/n)\n",
    "  return pd.DataFrame({'epoch':list(range(epochs)),'Loss':l_arr})\n",
    "BATCH_SIZE = 10\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "inception_results = train_1(model, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_8xWIPqnCXR"
   },
   "outputs": [],
   "source": [
    "#DENSENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfhSlmOsnh7v"
   },
   "outputs": [],
   "source": [
    "model = tv.models.densenet161(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLPDKFzGnEta"
   },
   "outputs": [],
   "source": [
    "transform_ = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((32, 32)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPXvqanOnG33"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('hymenoptera_data/train', transform)\n",
    "test_dataset = datasets.ImageFolder('hymenoptera_data/val', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qt4Sozo1nOWA"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghlqwhMHnWgB"
   },
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=2208, out_features=len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UafbGAXrnYLS"
   },
   "outputs": [],
   "source": [
    "\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GOk4Sv3naNf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "dense_results = train(model, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWu55sT_nbOk"
   },
   "outputs": [],
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUzPcsglno8r"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot\n",
    "plt.plot(res_results['epoch'], res_results['Loss'],label='Resnet')\n",
    "#plt.plot(vgg_results['epoch'], vgg_results['Loss'],label='VGG')\n",
    "plt.plot(inception_results ['epoch'], inception_results ['Loss'],label='Inception')\n",
    "plt.plot(dense_results ['epoch'],dense_results  ['Loss'],label='DenseNet')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2XnJlTFnqDT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
