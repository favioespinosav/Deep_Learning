{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd33a08-fd6b-40b2-bcba-c144f30958d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b89c46b-5257-4013-9ab6-5478dff98c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0, 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70fe53e3-24fd-430e-87be-91bb1255abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
    "    net.to(device)\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "            if i % 10 == 0:\n",
    "              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \" \n",
    "                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
    "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
    "        print('-' * 20)\n",
    "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
    "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45fbcf2-e345-46de-a7c5-107e04aff224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816f3aa2-053a-49b5-b565-9e4fdb7a4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((224, 224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63217314-c993-40f3-a356-859320c4157a",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98c7a3d5-19a0-4328-a8a3-ba14921ff567",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Flatten(),# 3d tensro to 1d\n",
    "    nn.Linear(6400, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86eddf77-1078-4767-81b2-4f273317750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "              ReLU-2           [-1, 96, 54, 54]               0\n",
      "         MaxPool2d-3           [-1, 96, 26, 26]               0\n",
      "            Conv2d-4          [-1, 256, 26, 26]         614,656\n",
      "              ReLU-5          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-6          [-1, 256, 12, 12]               0\n",
      "            Conv2d-7          [-1, 384, 12, 12]         885,120\n",
      "              ReLU-8          [-1, 384, 12, 12]               0\n",
      "            Conv2d-9          [-1, 384, 12, 12]       1,327,488\n",
      "             ReLU-10          [-1, 384, 12, 12]               0\n",
      "           Conv2d-11          [-1, 256, 12, 12]         884,992\n",
      "             ReLU-12          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-13            [-1, 256, 5, 5]               0\n",
      "          Flatten-14                 [-1, 6400]               0\n",
      "           Linear-15                 [-1, 4096]      26,218,496\n",
      "             ReLU-16                 [-1, 4096]               0\n",
      "          Dropout-17                 [-1, 4096]               0\n",
      "           Linear-18                 [-1, 4096]      16,781,312\n",
      "             ReLU-19                 [-1, 4096]               0\n",
      "          Dropout-20                 [-1, 4096]               0\n",
      "           Linear-21                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 10.22\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 188.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b5419c28-dec0-4724-a3a4-1509c378ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0. time since epoch: 2.463. Train acc: 0.117. Train Loss: 2.302\n",
      "Step 10. time since epoch: 29.936. Train acc: 0.114. Train Loss: 2.348\n",
      "Step 20. time since epoch: 58.440. Train acc: 0.247. Train Loss: 2.142\n",
      "Step 30. time since epoch: 87.069. Train acc: 0.372. Train Loss: 1.824\n",
      "Step 40. time since epoch: 115.854. Train acc: 0.475. Train Loss: 1.551\n",
      "Step 50. time since epoch: 144.508. Train acc: 0.549. Train Loss: 1.341\n",
      "Step 60. time since epoch: 173.514. Train acc: 0.601. Train Loss: 1.189\n",
      "Step 70. time since epoch: 202.803. Train acc: 0.641. Train Loss: 1.071\n",
      "Step 80. time since epoch: 231.832. Train acc: 0.678. Train Loss: 0.965\n",
      "Step 90. time since epoch: 261.006. Train acc: 0.707. Train Loss: 0.880\n",
      "Step 100. time since epoch: 290.201. Train acc: 0.730. Train Loss: 0.811\n",
      "Step 110. time since epoch: 319.686. Train acc: 0.749. Train Loss: 0.753\n",
      "Step 120. time since epoch: 349.286. Train acc: 0.766. Train Loss: 0.703\n",
      "Step 130. time since epoch: 378.594. Train acc: 0.781. Train Loss: 0.659\n",
      "Step 140. time since epoch: 407.862. Train acc: 0.794. Train Loss: 0.620\n",
      "Step 150. time since epoch: 437.369. Train acc: 0.806. Train Loss: 0.586\n",
      "Step 160. time since epoch: 466.972. Train acc: 0.816. Train Loss: 0.556\n",
      "Step 170. time since epoch: 497.076. Train acc: 0.825. Train Loss: 0.530\n",
      "Step 180. time since epoch: 526.750. Train acc: 0.832. Train Loss: 0.507\n",
      "Step 190. time since epoch: 556.582. Train acc: 0.839. Train Loss: 0.486\n",
      "Step 200. time since epoch: 586.173. Train acc: 0.846. Train Loss: 0.467\n",
      "Step 210. time since epoch: 616.013. Train acc: 0.852. Train Loss: 0.450\n",
      "Step 220. time since epoch: 645.734. Train acc: 0.857. Train Loss: 0.434\n",
      "Step 230. time since epoch: 675.066. Train acc: 0.862. Train Loss: 0.417\n",
      "--------------------\n",
      "epoch 1, loss 0.4129, train acc 0.864, test acc 0.976, time 723.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs  = 0.001, 1\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86902654-ea4a-4376-83a7-a7ca80963bc8",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a3621a8-320b-47fc-a9cf-1c4e47400770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vgg_block(num_convs, input_channels, num_channels):\n",
    "    blk = nn.Sequential(nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1), nn.ReLU())\n",
    "    for i in range(num_convs - 1):\n",
    "        blk.add_module(\"conv{}\".format(i), nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1))\n",
    "        blk.add_module(\"relu{}\".format(i), nn.ReLU())\n",
    "    blk.add_module(\"pool\", nn.MaxPool2d(2, stride=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a5db648-38bd-4eda-be9f-bb30b98dc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vgg(conv_arch):\n",
    "    net = nn.Sequential()\n",
    "\n",
    "    for i, (num_convs, input_ch, num_channels) in enumerate(conv_arch):\n",
    "        net.add_module(\"block{}\".format(i), vgg_block(num_convs, input_ch, num_channels))\n",
    "\n",
    "    \n",
    "    classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        \n",
    "        # nn.Linear(25088, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(6272, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "    net.add_module('classifier', classifier)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ed204ac-9795-4694-a109-5c2ccc443a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66007924-753f-453f-99da-d723cbfaf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(v[0], max(v[1] // ratio, 1), v[2] // ratio) for v in conv_arch]\n",
    "net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1d40e26-19a9-41d4-9739-8ce8856ef130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 16), (1, 16, 32), (2, 32, 64), (2, 64, 128), (2, 128, 128)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_conv_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8aca61f3-ce33-42f7-ba91-ca9c41755001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50176"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bb70039-c77d-4032-a4fc-3d436e50f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             160\n",
      "              ReLU-2         [-1, 16, 224, 224]               0\n",
      "         MaxPool2d-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]           4,640\n",
      "              ReLU-5         [-1, 32, 112, 112]               0\n",
      "         MaxPool2d-6           [-1, 32, 56, 56]               0\n",
      "            Conv2d-7           [-1, 64, 56, 56]          18,496\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12          [-1, 128, 28, 28]          73,856\n",
      "             ReLU-13          [-1, 128, 28, 28]               0\n",
      "           Conv2d-14          [-1, 128, 28, 28]         147,584\n",
      "             ReLU-15          [-1, 128, 28, 28]               0\n",
      "        MaxPool2d-16          [-1, 128, 14, 14]               0\n",
      "           Conv2d-17          [-1, 128, 14, 14]         147,584\n",
      "             ReLU-18          [-1, 128, 14, 14]               0\n",
      "           Conv2d-19          [-1, 128, 14, 14]         147,584\n",
      "             ReLU-20          [-1, 128, 14, 14]               0\n",
      "        MaxPool2d-21            [-1, 128, 7, 7]               0\n",
      "          Flatten-22                 [-1, 6272]               0\n",
      "           Linear-23                 [-1, 4096]      25,694,208\n",
      "             ReLU-24                 [-1, 4096]               0\n",
      "          Dropout-25                 [-1, 4096]               0\n",
      "           Linear-26                 [-1, 4096]      16,781,312\n",
      "             ReLU-27                 [-1, 4096]               0\n",
      "          Dropout-28                 [-1, 4096]               0\n",
      "           Linear-29                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 43,093,322\n",
      "Trainable params: 43,093,322\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 31.48\n",
      "Params size (MB): 164.39\n",
      "Estimated Total Size (MB): 196.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67e46d39-accd-459a-85ba-f5328817752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0. time since epoch: 2.963. Train acc: 0.082. Train Loss: 2.303\n",
      "Step 10. time since epoch: 34.919. Train acc: 0.103. Train Loss: 2.303\n",
      "Step 20. time since epoch: 67.279. Train acc: 0.103. Train Loss: 2.302\n",
      "Step 30. time since epoch: 99.903. Train acc: 0.107. Train Loss: 2.302\n",
      "Step 40. time since epoch: 132.689. Train acc: 0.108. Train Loss: 2.302\n",
      "Step 50. time since epoch: 165.912. Train acc: 0.123. Train Loss: 2.292\n",
      "Step 60. time since epoch: 199.295. Train acc: 0.177. Train Loss: 2.172\n",
      "Step 70. time since epoch: 232.103. Train acc: 0.254. Train Loss: 1.984\n",
      "Step 80. time since epoch: 265.396. Train acc: 0.326. Train Loss: 1.801\n",
      "Step 90. time since epoch: 298.995. Train acc: 0.389. Train Loss: 1.639\n",
      "Step 100. time since epoch: 331.987. Train acc: 0.441. Train Loss: 1.502\n",
      "Step 110. time since epoch: 365.464. Train acc: 0.486. Train Loss: 1.384\n",
      "Step 120. time since epoch: 399.007. Train acc: 0.523. Train Loss: 1.287\n",
      "Step 130. time since epoch: 432.726. Train acc: 0.556. Train Loss: 1.200\n",
      "Step 140. time since epoch: 466.436. Train acc: 0.585. Train Loss: 1.124\n",
      "Step 150. time since epoch: 500.348. Train acc: 0.610. Train Loss: 1.059\n",
      "Step 160. time since epoch: 533.878. Train acc: 0.631. Train Loss: 1.001\n",
      "Step 170. time since epoch: 567.792. Train acc: 0.651. Train Loss: 0.950\n",
      "Step 180. time since epoch: 601.728. Train acc: 0.668. Train Loss: 0.906\n",
      "Step 190. time since epoch: 635.348. Train acc: 0.683. Train Loss: 0.864\n",
      "Step 200. time since epoch: 668.961. Train acc: 0.697. Train Loss: 0.827\n",
      "Step 210. time since epoch: 702.237. Train acc: 0.710. Train Loss: 0.793\n",
      "Step 220. time since epoch: 736.031. Train acc: 0.722. Train Loss: 0.760\n",
      "Step 230. time since epoch: 769.443. Train acc: 0.733. Train Loss: 0.729\n",
      "--------------------\n",
      "epoch 1, loss 0.7203, train acc 0.737, test acc 0.980, time 828.5 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 1\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86419264-e06c-494c-9fbb-1019ebd851c2",
   "metadata": {},
   "source": [
    "# NiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7069c9ef-72ed-40ef-b8ff-53de12582b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(input_channels, num_channels, kernel_size, strides, padding):\n",
    "    blk = nn.Sequential(\n",
    "          nn.Conv2d(input_channels, num_channels, kernel_size, strides, padding),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(num_channels, num_channels, kernel_size=1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(num_channels, num_channels, kernel_size=1),\n",
    "          nn.ReLU()\n",
    "    )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "044393ec-deb8-4cc7-97ab-3eae6ebc1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AvgPool2d(5),\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76bb5be8-4abf-4354-b5f2-efea71f55fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "              ReLU-2           [-1, 96, 54, 54]               0\n",
      "            Conv2d-3           [-1, 96, 54, 54]           9,312\n",
      "              ReLU-4           [-1, 96, 54, 54]               0\n",
      "            Conv2d-5           [-1, 96, 54, 54]           9,312\n",
      "              ReLU-6           [-1, 96, 54, 54]               0\n",
      "         MaxPool2d-7           [-1, 96, 26, 26]               0\n",
      "            Conv2d-8          [-1, 256, 26, 26]         614,656\n",
      "              ReLU-9          [-1, 256, 26, 26]               0\n",
      "           Conv2d-10          [-1, 256, 26, 26]          65,792\n",
      "             ReLU-11          [-1, 256, 26, 26]               0\n",
      "           Conv2d-12          [-1, 256, 26, 26]          65,792\n",
      "             ReLU-13          [-1, 256, 26, 26]               0\n",
      "        MaxPool2d-14          [-1, 256, 12, 12]               0\n",
      "           Conv2d-15          [-1, 384, 12, 12]         885,120\n",
      "             ReLU-16          [-1, 384, 12, 12]               0\n",
      "           Conv2d-17          [-1, 384, 12, 12]         147,840\n",
      "             ReLU-18          [-1, 384, 12, 12]               0\n",
      "           Conv2d-19          [-1, 384, 12, 12]         147,840\n",
      "             ReLU-20          [-1, 384, 12, 12]               0\n",
      "        MaxPool2d-21            [-1, 384, 5, 5]               0\n",
      "          Dropout-22            [-1, 384, 5, 5]               0\n",
      "           Conv2d-23             [-1, 10, 5, 5]          34,570\n",
      "             ReLU-24             [-1, 10, 5, 5]               0\n",
      "           Conv2d-25             [-1, 10, 5, 5]             110\n",
      "             ReLU-26             [-1, 10, 5, 5]               0\n",
      "           Conv2d-27             [-1, 10, 5, 5]             110\n",
      "             ReLU-28             [-1, 10, 5, 5]               0\n",
      "        AvgPool2d-29             [-1, 10, 1, 1]               0\n",
      "          Flatten-30                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 1,992,166\n",
      "Trainable params: 1,992,166\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 24.20\n",
      "Params size (MB): 7.60\n",
      "Estimated Total Size (MB): 31.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2732669-9a6a-415a-9ea3-2714068371f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 1\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaa359-9059-4367-9941-4314964a0650",
   "metadata": {},
   "source": [
    "# GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "21f0d616-3ec6-4b40-9cf8-b54995280cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.module.Module"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "52ef5dc4-4006-445a-85be-418f70c10c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, ic, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.p1_1 = nn.Sequential(nn.Conv2d(ic, c1, kernel_size=1), nn.ReLU())\n",
    "        self.p2_1 = nn.Sequential(nn.Conv2d(ic, c2[0], kernel_size=1), nn.ReLU())\n",
    "        self.p2_2 = nn.Sequential(nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1), nn.ReLU())\n",
    "        self.p3_1 = nn.Sequential(nn.Conv2d(ic, c3[0], kernel_size=1), nn.ReLU())\n",
    "        self.p3_2 = nn.Sequential(nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2), nn.ReLU())\n",
    "        self.p4_1 = nn.Sequential(nn.MaxPool2d(3, stride=1, padding=1))\n",
    "        self.p4_2 = nn.Sequential(nn.Conv2d(ic, c4, kernel_size=1), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # Concatenate the outputs on the channel dimension.\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "59fe556a-2c7d-4b5d-b4b7-39ede54047e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f0e770ed-6c0d-4953-9c65-eafa6490d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b2 = nn.Sequential(\n",
    "       nn.Conv2d(64, 64, kernel_size=1),\n",
    "       nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0f24346a-b0b7-4d18-90fc-353ae107d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b3 = nn.Sequential(\n",
    "       Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "       Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "23b65891-b936-4d1f-a0bb-eab77a1b9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b4 = nn.Sequential(\n",
    "       Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "       Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "       Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "       Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "       Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1099ced1-886a-4b50-9f85-23dd47caca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b5 = nn.Sequential(\n",
    "       Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "       Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "       nn.AvgPool2d(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "32f2c779-70fc-402f-9594-cb88a9d17261",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Flatten(), nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a425718b-6d4c-4763-a44d-5fa2d0fc2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           3,200\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-3           [-1, 64, 56, 56]               0\n",
      "            Conv2d-4           [-1, 64, 56, 56]           4,160\n",
      "            Conv2d-5          [-1, 192, 56, 56]         110,784\n",
      "         MaxPool2d-6          [-1, 192, 28, 28]               0\n",
      "            Conv2d-7           [-1, 64, 28, 28]          12,352\n",
      "              ReLU-8           [-1, 64, 28, 28]               0\n",
      "            Conv2d-9           [-1, 96, 28, 28]          18,528\n",
      "             ReLU-10           [-1, 96, 28, 28]               0\n",
      "           Conv2d-11          [-1, 128, 28, 28]         110,720\n",
      "             ReLU-12          [-1, 128, 28, 28]               0\n",
      "           Conv2d-13           [-1, 16, 28, 28]           3,088\n",
      "             ReLU-14           [-1, 16, 28, 28]               0\n",
      "           Conv2d-15           [-1, 32, 28, 28]          12,832\n",
      "             ReLU-16           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-17          [-1, 192, 28, 28]               0\n",
      "           Conv2d-18           [-1, 32, 28, 28]           6,176\n",
      "             ReLU-19           [-1, 32, 28, 28]               0\n",
      "        Inception-20          [-1, 256, 28, 28]               0\n",
      "           Conv2d-21          [-1, 128, 28, 28]          32,896\n",
      "             ReLU-22          [-1, 128, 28, 28]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          32,896\n",
      "             ReLU-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 192, 28, 28]         221,376\n",
      "             ReLU-26          [-1, 192, 28, 28]               0\n",
      "           Conv2d-27           [-1, 32, 28, 28]           8,224\n",
      "             ReLU-28           [-1, 32, 28, 28]               0\n",
      "           Conv2d-29           [-1, 96, 28, 28]          76,896\n",
      "             ReLU-30           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32           [-1, 64, 28, 28]          16,448\n",
      "             ReLU-33           [-1, 64, 28, 28]               0\n",
      "        Inception-34          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-35          [-1, 480, 14, 14]               0\n",
      "           Conv2d-36          [-1, 192, 14, 14]          92,352\n",
      "             ReLU-37          [-1, 192, 14, 14]               0\n",
      "           Conv2d-38           [-1, 96, 14, 14]          46,176\n",
      "             ReLU-39           [-1, 96, 14, 14]               0\n",
      "           Conv2d-40          [-1, 208, 14, 14]         179,920\n",
      "             ReLU-41          [-1, 208, 14, 14]               0\n",
      "           Conv2d-42           [-1, 16, 14, 14]           7,696\n",
      "             ReLU-43           [-1, 16, 14, 14]               0\n",
      "           Conv2d-44           [-1, 48, 14, 14]          19,248\n",
      "             ReLU-45           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-46          [-1, 480, 14, 14]               0\n",
      "           Conv2d-47           [-1, 64, 14, 14]          30,784\n",
      "             ReLU-48           [-1, 64, 14, 14]               0\n",
      "        Inception-49          [-1, 512, 14, 14]               0\n",
      "           Conv2d-50          [-1, 160, 14, 14]          82,080\n",
      "             ReLU-51          [-1, 160, 14, 14]               0\n",
      "           Conv2d-52          [-1, 112, 14, 14]          57,456\n",
      "             ReLU-53          [-1, 112, 14, 14]               0\n",
      "           Conv2d-54          [-1, 224, 14, 14]         226,016\n",
      "             ReLU-55          [-1, 224, 14, 14]               0\n",
      "           Conv2d-56           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-57           [-1, 24, 14, 14]               0\n",
      "           Conv2d-58           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-59           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-60          [-1, 512, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-62           [-1, 64, 14, 14]               0\n",
      "        Inception-63          [-1, 512, 14, 14]               0\n",
      "           Conv2d-64          [-1, 128, 14, 14]          65,664\n",
      "             ReLU-65          [-1, 128, 14, 14]               0\n",
      "           Conv2d-66          [-1, 128, 14, 14]          65,664\n",
      "             ReLU-67          [-1, 128, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         295,168\n",
      "             ReLU-69          [-1, 256, 14, 14]               0\n",
      "           Conv2d-70           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-71           [-1, 24, 14, 14]               0\n",
      "           Conv2d-72           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-73           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-74          [-1, 512, 14, 14]               0\n",
      "           Conv2d-75           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-76           [-1, 64, 14, 14]               0\n",
      "        Inception-77          [-1, 512, 14, 14]               0\n",
      "           Conv2d-78          [-1, 112, 14, 14]          57,456\n",
      "             ReLU-79          [-1, 112, 14, 14]               0\n",
      "           Conv2d-80          [-1, 144, 14, 14]          73,872\n",
      "             ReLU-81          [-1, 144, 14, 14]               0\n",
      "           Conv2d-82          [-1, 288, 14, 14]         373,536\n",
      "             ReLU-83          [-1, 288, 14, 14]               0\n",
      "           Conv2d-84           [-1, 32, 14, 14]          16,416\n",
      "             ReLU-85           [-1, 32, 14, 14]               0\n",
      "           Conv2d-86           [-1, 64, 14, 14]          51,264\n",
      "             ReLU-87           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-88          [-1, 512, 14, 14]               0\n",
      "           Conv2d-89           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-90           [-1, 64, 14, 14]               0\n",
      "        Inception-91          [-1, 528, 14, 14]               0\n",
      "           Conv2d-92          [-1, 256, 14, 14]         135,424\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 160, 14, 14]          84,640\n",
      "             ReLU-95          [-1, 160, 14, 14]               0\n",
      "           Conv2d-96          [-1, 320, 14, 14]         461,120\n",
      "             ReLU-97          [-1, 320, 14, 14]               0\n",
      "           Conv2d-98           [-1, 32, 14, 14]          16,928\n",
      "             ReLU-99           [-1, 32, 14, 14]               0\n",
      "          Conv2d-100          [-1, 128, 14, 14]         102,528\n",
      "            ReLU-101          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-102          [-1, 528, 14, 14]               0\n",
      "          Conv2d-103          [-1, 128, 14, 14]          67,712\n",
      "            ReLU-104          [-1, 128, 14, 14]               0\n",
      "       Inception-105          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-106            [-1, 832, 7, 7]               0\n",
      "          Conv2d-107            [-1, 256, 7, 7]         213,248\n",
      "            ReLU-108            [-1, 256, 7, 7]               0\n",
      "          Conv2d-109            [-1, 160, 7, 7]         133,280\n",
      "            ReLU-110            [-1, 160, 7, 7]               0\n",
      "          Conv2d-111            [-1, 320, 7, 7]         461,120\n",
      "            ReLU-112            [-1, 320, 7, 7]               0\n",
      "          Conv2d-113             [-1, 32, 7, 7]          26,656\n",
      "            ReLU-114             [-1, 32, 7, 7]               0\n",
      "          Conv2d-115            [-1, 128, 7, 7]         102,528\n",
      "            ReLU-116            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-117            [-1, 832, 7, 7]               0\n",
      "          Conv2d-118            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-119            [-1, 128, 7, 7]               0\n",
      "       Inception-120            [-1, 832, 7, 7]               0\n",
      "          Conv2d-121            [-1, 384, 7, 7]         319,872\n",
      "            ReLU-122            [-1, 384, 7, 7]               0\n",
      "          Conv2d-123            [-1, 192, 7, 7]         159,936\n",
      "            ReLU-124            [-1, 192, 7, 7]               0\n",
      "          Conv2d-125            [-1, 384, 7, 7]         663,936\n",
      "            ReLU-126            [-1, 384, 7, 7]               0\n",
      "          Conv2d-127             [-1, 48, 7, 7]          39,984\n",
      "            ReLU-128             [-1, 48, 7, 7]               0\n",
      "          Conv2d-129            [-1, 128, 7, 7]         153,728\n",
      "            ReLU-130            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-131            [-1, 832, 7, 7]               0\n",
      "          Conv2d-132            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-133            [-1, 128, 7, 7]               0\n",
      "       Inception-134           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-135           [-1, 1024, 1, 1]               0\n",
      "         Flatten-136                 [-1, 1024]               0\n",
      "          Linear-137                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,977,530\n",
      "Trainable params: 5,977,530\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 63.36\n",
      "Params size (MB): 22.80\n",
      "Estimated Total Size (MB): 86.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b40fe-2524-4b29-a9ed-806e88882c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6d66c27f-dcd2-474e-9305-22ff182ed0e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 7, 7], expected input[256, 3, 224, 224] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [206], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[1;32m     13\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 7, 7], expected input[256, 3, 224, 224] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 1\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacf5ee-3d6b-41b0-bb2c-e1f3f6f85ba1",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b8a2a-fe71-4378-b465-af6481d13931",
   "metadata": {},
   "outputs": [],
   "source": [
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(3),\n",
    "    tv.transforms.Resize((224, 224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32009de1-a906-450b-a57b-9ecda6187d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9c16b-d0aa-488f-9a28-69c0f423cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3228852-37ff-4a13-8432-75833d68718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   :\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd7c35-cbee-4731-8341-d88967b126da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e10d0-f260-47c9-9b54-db7e4480ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=2208, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980af151-a922-4fc3-889d-aecbf8c25cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92933c3-00c0-4b12-a658-c0ec01eea0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887c12b-78df-4d1b-94bc-c741e496eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_iter, test_iter, trainer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f521b-8a06-4f26-b7bc-23cb13b2e639",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b8f97-865a-4071-8b77-b8fff4993796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a0cef-b6a4-4097-96e6-2723f43c9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   :\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71f457-d979-4f4f-8791-85251b524df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Linear(in_features=2208, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be67f82-2b0a-43fb-8a46-0042c16cf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b16e09-f3d2-48c5-9c1c-5442f12d965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326ac50-d1e1-4db6-a1f1-272ef19b6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train(model, train_iter, test_iter, trainer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ab88c-7de2-47b3-bee7-286594604795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813329a0-a637-401f-b946-e9c65ac6f076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de69b1-f438-436e-9398-7dbff45cb5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c595c63-abed-4771-ae98-911280089822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "744918ce-3764-4c63-881b-883e320b9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3620720938568087\n",
      "Epoch 1000, Loss: 0.24818488189413446\n",
      "Epoch 2000, Loss: 0.13513528120338808\n",
      "Epoch 3000, Loss: 0.004166378770697759\n",
      "Epoch 4000, Loss: 0.001633221852659256\n",
      "Epoch 5000, Loss: 0.0009742008772452404\n",
      "Epoch 6000, Loss: 0.0006828323229207705\n",
      "Epoch 7000, Loss: 0.0005212061530006792\n",
      "Epoch 8000, Loss: 0.00041933929578465287\n",
      "Epoch 9000, Loss: 0.0003496366610936228\n",
      "[[0.45908929]\n",
      " [0.99055395]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#      \n",
    "X = np.array([[0, 1, 0],\n",
    "              [1, 1, 1],\n",
    "              [1, 0, 0],\n",
    "              [0, 1, 1]])\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "#   \n",
    "input_neurons = X.shape[1]  #   \n",
    "hidden1_neurons = 8 \n",
    "hidden2_neurons = 4  #      \n",
    "output_neurons = 1  #   \n",
    "epochs = 10000  #   \n",
    "learning_rate = 0.1  #  \n",
    "\n",
    "#     \n",
    "w1 = np.random.uniform(size=(input_neurons, hidden1_neurons))\n",
    "w2 = np.random.uniform(size=(hidden1_neurons, hidden2_neurons))\n",
    "w3 = np.random.uniform(size=(hidden2_neurons, output_neurons))\n",
    "\n",
    "#   (sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#   (MSE)\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "#  \n",
    "for i in range(epochs):\n",
    "    #   \n",
    "    hidden1_layer = sigmoid(np.dot(X, w1))\n",
    "    hidden2_layer = sigmoid(np.dot(hidden1_layer, w2))\n",
    "    output_layer = sigmoid(np.dot(hidden2_layer, w3))\n",
    "\n",
    "    #  \n",
    "    error = np.mean(np.square(y - output_layer))\n",
    "    error = output_layer - y \n",
    "\n",
    "    #        \n",
    "    d_output = error * output_layer * (1 - output_layer)\n",
    "    d_hidden2 = hidden2_layer * (1 - hidden2_layer) * np.dot(d_output, w3.T)\n",
    "    d_hidden1 = hidden1_layer * (1 - hidden1_layer) * np.dot(d_hidden2, w2.T)\n",
    "    w3 -= learning_rate * np.dot(hidden2_layer.T, d_output)\n",
    "    w2 -= learning_rate * np.dot(hidden1_layer.T, d_hidden2)\n",
    "    w1 -= learning_rate * np.dot(X.T, d_hidden1)\n",
    "\n",
    "    #    \n",
    "    if i % 1000 == 0:\n",
    "        loss = mse_loss(y, output_layer)\n",
    "        print(f\"Epoch {i}, Loss: {loss}\")\n",
    "\n",
    "#   \n",
    "test_input = np.array([[0, 0, 1],\n",
    "                       [1, 0, 1]])\n",
    "hidden1_layer = sigmoid(np.dot(test_input, w1))\n",
    "hidden2_layer = sigmoid(np.dot(hidden1_layer, w2))\n",
    "test_output = sigmoid(np.dot(hidden2_layer, w3))\n",
    "print(test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8141d14-b397-40eb-947c-4c60d72bef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1d459-f88c-492e-b151-dbd81baf5b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea832ba-b1f0-4f79-8d62-90d82fb86308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fe2dc-fe5a-4228-8f0d-67fc1fff042a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c7442-ba85-4ecc-bb1d-073a65fc8599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c3e2a-8d90-49e4-acda-8811fd1d72be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f3e0c-70ab-4700-8dd9-113bbf6cb522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f9d28-b190-4c45-adaf-a88e6e0806c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f435d-038f-4c72-9dd7-2a2805d8db18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbc1aab-a7b4-449e-8d03-9eb0a3d67fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.62434536 -0.61175641]\n",
      "[-inf -inf]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=1)\n",
    "def gradient_descent(X, y, learning_rate=0.01, epochs=10000):\n",
    "    #   \n",
    "    weights = np.random.randn(X.shape[1])\n",
    "    print(weights)\n",
    "    #  \n",
    "    for epoch in range(epochs):\n",
    "        #  \n",
    "        y_pred = X.dot(weights)\n",
    "        #  \n",
    "        error = ( y- y_pred  )\n",
    "        #  \n",
    "        gradient = X.T.dot(error) / X.shape[0]\n",
    "         #  \n",
    "        weights -= learning_rate * 2*gradient\n",
    "    return weights\n",
    "\n",
    "#  \n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "w = np.array([1,2])\n",
    "y = X.dot(w)\n",
    "\n",
    "weights = gradient_descent(X, y)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52260fb9-9456-49de-b9ba-632eba91064c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,3) and (4,1) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,3) and (4,1) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "X.T.dot(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48f74f1-ed68-491f-a995-7e97c4d7afe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"204805805314797448912\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf6a0d-058f-4051-bf20-1a45fa4818f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
