{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL1mSOU8FWmj"
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPgV_QfhFhtP",
    "outputId": "9c308748-6fa1-4d80-c94f-ea3f0697d65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-21 09:47:29--  https://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15460248 (15M) [application/zip]\n",
      "Saving to: ‘rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  14.74M  54.3MB/s    in 0.3s    \n",
      "\n",
      "2023-06-21 09:47:29 (54.3 MB/s) - ‘rus-eng.zip’ saved [15460248/15460248]\n",
      "\n",
      "Archive:  rus-eng.zip\n",
      "  inflating: rus.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/rus-eng.zip\n",
    "!unzip rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zk7NvfyJFyAd",
    "outputId": "e31f2ed9-92eb-44d2-ccc7-1e6e8851b8e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
      "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
      "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
      "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
      "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
      "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
      "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
      "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
      "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
      "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!tail rus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlNKTBpxF55e"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2TjecJgGDfM"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?А-Яа-яёЁ]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klnpQB-1HSwN"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('rus.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[:-1]] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj-anV1lHUql"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggQEx2GHHWDt",
    "outputId": "98d01b5b-aedf-497d-f547-c00a133e9b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 467119 sentence pairs\n",
      "Trimmed to 27228 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 9939\n",
      "eng 4229\n",
      "['мы все на однои стороне .', 'we re all on the same side .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L888dVIQIZnV"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veXzQq4EJAOg"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REHwCqWXJBhe"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrco_75IJDzZ"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na_Upd0TJFSD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSjUwUmCJG1z"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydCDg5R3JIb9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYWtd5W0JJ4F"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg8bzi8GJLOc"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLLIKbi4JNb5",
    "outputId": "20dad4b9-4fe6-47cf-fd1a-92e8e42ecf38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 13m 55s) (5000 6%) 3.1163\n",
      "1m 54s (- 12m 26s) (10000 13%) 2.6301\n",
      "2m 49s (- 11m 19s) (15000 20%) 2.3558\n",
      "3m 43s (- 10m 14s) (20000 26%) 2.1441\n",
      "4m 38s (- 9m 16s) (25000 33%) 1.9697\n",
      "5m 32s (- 8m 18s) (30000 40%) 1.8148\n",
      "6m 26s (- 7m 21s) (35000 46%) 1.7260\n",
      "7m 20s (- 6m 25s) (40000 53%) 1.6222\n",
      "8m 14s (- 5m 29s) (45000 60%) 1.5344\n",
      "9m 9s (- 4m 34s) (50000 66%) 1.4875\n",
      "10m 2s (- 3m 39s) (55000 73%) 1.3979\n",
      "10m 56s (- 2m 44s) (60000 80%) 1.3655\n",
      "11m 50s (- 1m 49s) (65000 86%) 1.3080\n",
      "12m 44s (- 0m 54s) (70000 93%) 1.2327\n",
      "13m 38s (- 0m 0s) (75000 100%) 1.1861\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5v22ZEQjJP5U",
    "outputId": "c5b83a07-e706-485c-b6eb-971efb790be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я сегодня выходнои .\n",
      "= i m off today .\n",
      "< i m a today today . <EOS>\n",
      "\n",
      "> я жду свою подругу .\n",
      "= i m waiting for my girlfriend .\n",
      "< i m waiting for my life . <EOS>\n",
      "\n",
      "> вы себе противоречите .\n",
      "= you re contradicting yourselves .\n",
      "< you re contradicting yourself . <EOS>\n",
      "\n",
      "> вы у меня в руках .\n",
      "= you re in my hands .\n",
      "< you re in my hands . <EOS>\n",
      "\n",
      "> мы устраиваем тому вечеринку на день рождения .\n",
      "= we re throwing tom a birthday party .\n",
      "< we re expecting tom a a party . <EOS>\n",
      "\n",
      "> их там никогда нет .\n",
      "= they re never there .\n",
      "< they re never there . <EOS>\n",
      "\n",
      "> я не злюсь на тома .\n",
      "= i m not mad at tom .\n",
      "< i m not mad at tom . <EOS>\n",
      "\n",
      "> он убирается в шкафу .\n",
      "= he s cleaning out his closet .\n",
      "< he s the out of the . <EOS>\n",
      "\n",
      "> я рад что ты поправился .\n",
      "= i m glad you ve recovered .\n",
      "< i m glad you ve recovered . <EOS>\n",
      "\n",
      "> я уверен что у него получится .\n",
      "= i m sure that he ll succeed .\n",
      "< i m sure that he will succeed . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0N4YRCGvJ0Rl"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.gru_2 = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output, hidden = self.gru_2(output, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUFkLj_HMZBV"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN_2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.gru_2 = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output, hidden = self.gru_2(output, hidden)\n",
    "\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTJQUzCVMkj9",
    "outputId": "9161dacd-aab1-49cf-a26e-c771860616aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 36s (- 92m 28s) (5000 6%) 3.3091\n",
      "13m 0s (- 84m 36s) (10000 13%) 2.9153\n",
      "19m 34s (- 78m 17s) (15000 20%) 2.7432\n",
      "26m 10s (- 71m 58s) (20000 26%) 2.6181\n",
      "32m 58s (- 65m 56s) (25000 33%) 2.4974\n",
      "39m 42s (- 59m 34s) (30000 40%) 2.3459\n",
      "46m 23s (- 53m 1s) (35000 46%) 2.2431\n",
      "53m 2s (- 46m 24s) (40000 53%) 2.1287\n",
      "59m 40s (- 39m 47s) (45000 60%) 2.0306\n",
      "66m 23s (- 33m 11s) (50000 66%) 1.9391\n",
      "73m 1s (- 26m 33s) (55000 73%) 1.8661\n",
      "79m 41s (- 19m 55s) (60000 80%) 1.7960\n",
      "86m 21s (- 13m 17s) (65000 86%) 1.7235\n",
      "92m 58s (- 6m 38s) (70000 93%) 1.6648\n",
      "99m 30s (- 0m 0s) (75000 100%) 1.5898\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN_2(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN_2(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UF5sdyuvMoGs",
    "outputId": "ab08a76f-5da2-4dec-b599-18fae7f7b231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> они чистые .\n",
      "= they re clean .\n",
      "< they re happy . <EOS>\n",
      "\n",
      "> мы просим вас не делать этого .\n",
      "= we re asking you not to do that .\n",
      "< we re asking you not to do that . <EOS>\n",
      "\n",
      "> я в плохом настроении .\n",
      "= i m in a bad mood .\n",
      "< i m in a bad mood . <EOS>\n",
      "\n",
      "> ты мне не поверишь .\n",
      "= you re not going to believe me .\n",
      "< you re not going to . . <EOS>\n",
      "\n",
      "> он обедает .\n",
      "= he is having lunch .\n",
      "< he is a . <EOS>\n",
      "\n",
      "> вы опять здесь .\n",
      "= you re back again .\n",
      "< you re early here . <EOS>\n",
      "\n",
      "> я глупыи .\n",
      "= i m stupid .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> они студентки .\n",
      "= they re students .\n",
      "< they re young . <EOS>\n",
      "\n",
      "> я все еще в австралии .\n",
      "= i m still in australia .\n",
      "< i m still in australia . <EOS>\n",
      "\n",
      "> я устала так же как и ты .\n",
      "= i m just as tired as you are .\n",
      "< i m as strong as you are . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8vLTGS6vxnF"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,num_layers=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "\n",
    "\n",
    "        output, hidden = self.lstm(output,hidden )\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        h_0, c_0 = torch.zeros(2, 1, 1, self.hidden_size, device=device)\n",
    "\n",
    "        return h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUsDDLD3DOfm"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbGy1Zb3DSI8",
    "outputId": "7c7fb182-792e-44b4-b6c1-8699823c3035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 2s (- 14m 40s) (5000 6%) 3.2141\n",
      "2m 1s (- 13m 6s) (10000 13%) 2.7587\n",
      "3m 0s (- 12m 3s) (15000 20%) 2.5622\n",
      "3m 59s (- 10m 57s) (20000 26%) 2.3531\n",
      "4m 56s (- 9m 53s) (25000 33%) 2.2118\n",
      "5m 55s (- 8m 53s) (30000 40%) 2.0824\n",
      "6m 54s (- 7m 54s) (35000 46%) 1.9858\n",
      "7m 53s (- 6m 54s) (40000 53%) 1.8880\n",
      "8m 56s (- 5m 57s) (45000 60%) 1.8127\n",
      "9m 55s (- 4m 57s) (50000 66%) 1.7303\n",
      "11m 5s (- 4m 1s) (55000 73%) 1.6780\n",
      "12m 8s (- 3m 2s) (60000 80%) 1.5777\n",
      "13m 8s (- 2m 1s) (65000 86%) 1.5299\n",
      "14m 8s (- 1m 0s) (70000 93%) 1.4794\n",
      "15m 5s (- 0m 0s) (75000 100%) 1.3910\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN_LSTM(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN_LSTM(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCyehRnnDdKL",
    "outputId": "2ca55a0e-e467-43c5-8ad9-4045798e0a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я уверен что том едет .\n",
      "= i m sure tom is on his way .\n",
      "< i m sure tom will be . <EOS>\n",
      "\n",
      "> вы такая злая .\n",
      "= you re so mean .\n",
      "< you re so funny . <EOS>\n",
      "\n",
      "> мы не солдаты .\n",
      "= we re not soldiers .\n",
      "< we re not a . <EOS>\n",
      "\n",
      "> я для тебя слишком старыи .\n",
      "= i m too old for you .\n",
      "< i m too old for you . <EOS>\n",
      "\n",
      "> я в ужасе .\n",
      "= i m horrified .\n",
      "< i m in . <EOS>\n",
      "\n",
      "> мы рассчитываем на вашу финансовую помощь .\n",
      "= we are counting on you for financial help .\n",
      "< we re counting on you . <EOS>\n",
      "\n",
      "> вы так молоды .\n",
      "= you re so young .\n",
      "< you re so young . <EOS>\n",
      "\n",
      "> они все еще в доступе .\n",
      "= they re still available .\n",
      "< they re still in . <EOS>\n",
      "\n",
      "> простите что обидел вас .\n",
      "= i m sorry that i hurt you .\n",
      "< i m sorry i hurt you . <EOS>\n",
      "\n",
      "> вы просто констатируете очевидное .\n",
      "= you are just stating the obvious .\n",
      "< you re just the wrong . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUpnBW_zQBHO"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN_LSTM_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN_LSTM_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,num_layers=1)\n",
    "        self.lstm_2 = nn.LSTM(hidden_size, hidden_size,num_layers=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "\n",
    "\n",
    "        output, hidden = self.lstm(output,hidden )\n",
    "        output, hidden = self.lstm_2(output,hidden )\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        h_0, c_0 = torch.zeros(2, 1, 1, self.hidden_size, device=device)\n",
    "\n",
    "        return h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-Nf1qK0QGJM"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN_LSTM_2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN_LSTM_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.lstm_2 = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output, hidden = self.lstm_2(output, hidden)\n",
    "\n",
    "\n",
    "\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clM0LooYQpP6",
    "outputId": "86263b80-745f-436d-d699-fb9d46d04f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 2s (- 140m 33s) (5000 6%) 3.3517\n",
      "20m 9s (- 131m 4s) (10000 13%) 3.1232\n",
      "30m 21s (- 121m 25s) (15000 20%) 3.0408\n",
      "40m 39s (- 111m 49s) (20000 26%) 2.9779\n",
      "50m 53s (- 101m 47s) (25000 33%) 2.7702\n",
      "61m 12s (- 91m 49s) (30000 40%) 2.6848\n",
      "71m 43s (- 81m 57s) (35000 46%) 2.6350\n",
      "82m 17s (- 72m 0s) (40000 53%) 2.5830\n",
      "92m 35s (- 61m 43s) (45000 60%) 2.5534\n",
      "103m 19s (- 51m 39s) (50000 66%) 2.4694\n",
      "114m 4s (- 41m 28s) (55000 73%) 2.3959\n",
      "124m 48s (- 31m 12s) (60000 80%) 2.3742\n",
      "135m 32s (- 20m 51s) (65000 86%) 2.2904\n",
      "146m 26s (- 10m 27s) (70000 93%) 2.2644\n",
      "157m 8s (- 0m 0s) (75000 100%) 2.1784\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN_LSTM_2(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN_LSTM_2(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Qy3iaakQyVd",
    "outputId": "a48e9915-2b1b-4714-a6a1-881f48183dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> вам не угодишь .\n",
      "= you re a hard person to please .\n",
      "< you re not as young as i . <EOS>\n",
      "\n",
      "> ты ведь не учитель ?\n",
      "= you re not a teacher are you ?\n",
      "< you re not aren are you you ? <EOS>\n",
      "\n",
      "> я не собираюсь вам ничего говорить .\n",
      "= i m not going to tell you anything .\n",
      "< i m not going to go you . <EOS>\n",
      "\n",
      "> ты теперь мужчина .\n",
      "= you re a man now .\n",
      "< you re a little . <EOS>\n",
      "\n",
      "> у меня перерыв .\n",
      "= i m taking a break .\n",
      "< i m an . <EOS>\n",
      "\n",
      "> я почти дописал отчет .\n",
      "= i m almost finished writing the report .\n",
      "< i m just an adult . <EOS>\n",
      "\n",
      "> я человек широких взглядов .\n",
      "= i m open minded .\n",
      "< i m a little . . <EOS>\n",
      "\n",
      "> я впервые женюсь .\n",
      "= i m getting married for the first time .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> ты самыи умныи у нас в классе .\n",
      "= you re the smartest one in our class .\n",
      "< you re going to to than i . <EOS>\n",
      "\n",
      "> я откладываю на старость .\n",
      "= i m saving up for my old age .\n",
      "< i m a to . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkM8YowsQ1VG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
