{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dffdf45-5104-4d09-91ef-64db80a8b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06876d02-bc81-403c-91d2-7a0fb31baac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = torch.randint(0,9,(5000,25))\n",
    "X_2 = torch.randint(0,9,(5000,75))\n",
    "X_3 = torch.randint(0,9,(5000,125))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3a2868-275c-49ea-9385-2f6b83f036e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(X_1):\n",
    "  Y = X_1.clone()\n",
    "  Y[:, 1:] = (Y[:, 1:] + Y[:,[0]])%10\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02df100-3714-4807-ba50-c193e76b4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = make_target(X_1)\n",
    "Y_2 = make_target(X_2)\n",
    "Y_3 = make_target(X_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549bb88-7cd0-4c55-8209-1d2f93f68c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346159f6-2ca0-4277-9ff9-8510ddc42ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "      \n",
    "        self.output = nn.Linear(num_hiddens, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)\n",
    "        predictions = self.output(state[0])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce976c99-bee9-42c1-b57c-179a8c18d056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37131f6-4b63-4e74-ace4-52c674797b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_test(X,Y):\n",
    "  BATCH_SIZE=2048\n",
    "  X_train = X[:int(0.7*len(X))] \n",
    "  X_test = X[int(0.7*len(X)):]\n",
    "  Y_train = Y[:int(0.7*len(Y))] \n",
    "  Y_test = Y[int(0.7*len(Y)):] \n",
    "   \n",
    "  results = {'LSTM':[],'GRU':[],'RNN':[]}\n",
    "  for j,model_type in enumerate(['LSTM','GRU','RNN']):\n",
    "    if model_type == 'LSTM':\n",
    "      model = NeuralNetwork(nn.LSTM, 10, 64, 1024, 10)\n",
    "    elif model_type == 'RNN': \n",
    "      model = NeuralNetwork(nn.RNN, 10, 64, 1024, 10)\n",
    "    else:\n",
    "      model = NeuralNetwork(nn.GRU, 10, 64, 1024, 10)\n",
    "      \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    for ep in range(100):\n",
    "      start = time.time()\n",
    "      train_loss = 0.\n",
    "      train_passed = 0\n",
    "  \n",
    "      model.train()\n",
    "     \n",
    "    #  X_b, y_b = X_b.cuda(), y_b.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      answers = model.forward(X_train)\n",
    "      if len(answers.size()) == 3:\n",
    "        answers = answers[-1,:,:]\n",
    "      loss = criterion(answers, Y_train.flatten())\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_passed += 1\n",
    "        \n",
    "      model.eval()\n",
    "\n",
    "      acc_sum, n = 0, 0\n",
    "    \n",
    " \n",
    "      y_pred = model(X_test)\n",
    "      if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred[-1,:,:]\n",
    "      acc_sum += (y_pred.argmax(axis=1) == Y_test.flatten())).sum()\n",
    "      n += Y.test[0]\n",
    "      results[model_type].append(acc_sum.item() / n)  \n",
    "      if ep%50 == 0 :\n",
    "\n",
    "      \n",
    "        print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f} AUC {:3f}\".format(ep, time.time() - start, train_loss / train_passed,acc_sum.item() / n))\n",
    "        \n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aba0bf4e-5d4a-4890-8955-1e3a4a346d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X_1, Y_1, test_size=0.33, random_state=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4d3a2a-5e81-4e59-b832-cc606011062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0, 5,  ..., 8, 6, 7],\n",
       "        [3, 0, 0,  ..., 8, 0, 3],\n",
       "        [4, 8, 2,  ..., 3, 2, 4],\n",
       "        ...,\n",
       "        [0, 8, 8,  ..., 1, 4, 2],\n",
       "        [6, 4, 6,  ..., 2, 6, 6],\n",
       "        [8, 0, 3,  ..., 2, 7, 8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1[:int(0.7*len(X_1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b25ac728-878e-47c6-b66b-288fec21e986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 4,  ..., 6, 5, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f8d40d7-c2b4-42b9-814d-0615099f76de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 7.386, Train loss: 2.216 AUC 0.133333\n",
      "Epoch 50. Time: 8.191, Train loss: 2.191 AUC 0.141120\n",
      "Epoch 0. Time: 30.524, Train loss: 2.212 AUC 0.141120\n",
      "Epoch 50. Time: 4.705, Train loss: 2.192 AUC 0.141120\n",
      "Epoch 0. Time: 1.731, Train loss: 2.208 AUC 0.141120\n",
      "Epoch 50. Time: 1.881, Train loss: 2.194 AUC 0.141120\n"
     ]
    }
   ],
   "source": [
    "res_1 = train_test(X_1.reshape(-1,1),Y_1.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92389cf-4bae-4993-856a-bd8c556d4a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 22.267, Train loss: 2.209 AUC 0.113013\n"
     ]
    }
   ],
   "source": [
    "res_2 = train_test(X_2.reshape(-1,1),Y_2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19685845-42a3-4298-b55b-38cfb5368928",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3 = train_test(X_3.reshape(-1,1),Y_3.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79312285-236e-4fb2-b1e9-a7cc6004f817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
