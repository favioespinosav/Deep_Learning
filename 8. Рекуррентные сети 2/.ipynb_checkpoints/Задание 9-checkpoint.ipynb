{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iHah9Vq74t0e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import random\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-bs1_g342Nh",
    "outputId": "8e6e23d9-bf01-4530-dce5-1442ec442ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-11 11:40:57--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.133.216, 52.217.199.0, 52.216.221.176, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.133.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 600901 (587K) [text/plain]\n",
      "Saving to: ‘nietzsche.txt’\n",
      "\n",
      "nietzsche.txt       100%[===================>] 586.82K  1015KB/s    in 0.6s    \n",
      "\n",
      "2023-06-11 11:40:58 (1015 KB/s) - ‘nietzsche.txt’ saved [600901/600901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArE9Sysh5EDE",
    "outputId": "ae2671ba-c31b-4b86-e797-e012e256e790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 600893\n"
     ]
    }
   ],
   "source": [
    "with open('nietzsche.txt', encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('length:', len(text))\n",
    "text = re.sub('[^a-z ]', ' ', text)\n",
    "text = re.sub('\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ijyo7gcL49kz",
    "outputId": "738b82e2-1ea3-41d0-ba9f-422ae4b659af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface supposing that truth is a woman what then is there not ground for suspecting that all philos'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iNiH2xET5HxF"
   },
   "outputs": [],
   "source": [
    "INDEX_TO_CHAR = sorted(list(set(text)))\n",
    "CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAer4W2RYfhr",
    "outputId": "964f954a-7b56-4ed4-a178-5d3fd87623cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4EeJBub5ueL",
    "outputId": "6e6de311-5399-43e8-e49b-4e708eebeb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sents: 193075\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 40\n",
    "STEP = 3\n",
    "SENTENCES = []\n",
    "NEXT_CHARS = []\n",
    "for i in range(0, len(text) - MAX_LEN, STEP):\n",
    "    SENTENCES.append(text[i: i + MAX_LEN])\n",
    "    NEXT_CHARS.append(text[i + MAX_LEN])\n",
    "print('Num sents:', len(SENTENCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHPHQII_6MUV",
    "outputId": "d48cb0da-193f-478e-e011-0cc3fa05c82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = torch.zeros((len(SENTENCES), MAX_LEN), dtype=int)\n",
    "Y = torch.zeros((len(SENTENCES)), dtype=int)\n",
    "for i, sentence in enumerate(SENTENCES):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t] = CHAR_TO_INDEX[char]\n",
    "    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7MP7Jzi7PAN",
    "outputId": "c6d57fcb-d912-4b43-a2e8-17a46e4a8003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[16, 18,  5,  6,  1,  3,  5,  0, 19, 21, 16, 16, 15, 19,  9, 14,  7,  0,\n",
       "          20,  8,  1, 20,  0, 20, 18, 21, 20,  8,  0,  9, 19,  0,  1,  0, 23, 15,\n",
       "          13,  1, 14,  0]]),\n",
       " tensor(23))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1], Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4XKb2CyB6nwL"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "psIcSGM27YPL"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = nn.Linear(num_hiddens, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)\n",
    "        predictions = self.output(state[0].squeeze())\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wHDuSE8A7ssc"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(nn.GRU, len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvKPD9L9zJal",
    "outputId": "8a69e7a2-ef45-4acb-af30-58ed5b20f316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([193075, 40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTCG-ESC74UK",
    "outputId": "183a612f-2a3a-4a5a-87a7-f355a47f924f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0480,  0.1568,  0.1112,  0.0175,  0.0107,  0.1489,  0.1690,  0.1694,\n",
       "         0.0486,  0.0159, -0.1735, -0.0015,  0.1923, -0.1247,  0.0147,  0.0537,\n",
       "         0.1016,  0.0382,  0.1405,  0.0244,  0.0070, -0.0086,  0.2117, -0.1352,\n",
       "         0.0935,  0.1106, -0.1326], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gch6FQl8x6Hj"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(INDEX_TO_CHAR), 15)\n",
    "rnn = nn.LSTM(15,128, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJsUqfxYeq0b",
    "outputId": "fef78aac-7f25-4225-f2e0-37a661d91676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 40, 128]),\n",
       " 2,\n",
       " torch.Size([1, 10, 128]),\n",
       " torch.Size([1, 10, 128]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, s = rnn(embedding(X[0:10]))\n",
    "o.shape, len(s), s[0].shape, s[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qbiqECBCP4Bv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 40, 128]), 1, torch.Size([10, 128]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.GRU(15,128, batch_first=True)\n",
    "o, s = rnn(embedding(X[0:10]))\n",
    "o.shape, len(s), s[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "evDHlyNOykBr"
   },
   "outputs": [],
   "source": [
    "o, s = rnn(embedding(X[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hYTukwkykHJ",
    "outputId": "f75b46be-f6ab-4528-8e1c-b0e47dba0b06"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m o\u001b[38;5;241m.\u001b[39mshape, s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "o.shape, s[0].shape, s[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jbeKFkwdFclg"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ZQpkKJV_76dq"
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    softmaxed = torch.softmax(preds, 0)\n",
    "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
    "    return probas.argmax()\n",
    "\n",
    "def generate_text():\n",
    "    start_index = random.randint(0, len(text) - MAX_LEN - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + MAX_LEN]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(MAX_LEN):\n",
    "        x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
    "        for t, char in enumerate(generated[-MAX_LEN:]):\n",
    "            x_pred[0, t] = CHAR_TO_INDEX[char]\n",
    "\n",
    "        preds = model(x_pred)\n",
    "        next_char = INDEX_TO_CHAR[sample(preds)]\n",
    "        generated = generated + next_char\n",
    "\n",
    "    print(generated[:MAX_LEN] + '|' + generated[MAX_LEN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([51,50,1,49,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for i in a :\n",
    "  p.append(torch.exp(i)/torch.sum(torch.exp(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.FloatTensor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32., 10.,  0.,  8.,  0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.multinomial.Multinomial (50,p).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [91], line 21\u001b[0m, in \u001b[0;36mmultinomial\u001b[0;34m(n, pvals, size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     19\u001b[0m     size \u001b[38;5;241m=\u001b[39m (size, )\n\u001b[0;32m---> 21\u001b[0m result_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m [k]\n\u001b[1;32m     22\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    " multinomial(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "hylQYY8H_Lw2"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qshorynU9-Cx",
    "outputId": "e2b45154-9cf2-4799-d66a-2eb9fc5a92fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 21.569, Train loss: 1.307\n",
      "y seductive atmosphere of the moral maxi|sm and thys towards soliteness to self s\n",
      "Epoch 1. Time: 22.089, Train loss: 1.291\n",
      "es not generally consist in their confli|ct just a demparous heself before eye an\n",
      "Epoch 2. Time: 23.706, Train loss: 1.278\n",
      "that unscrupulous enthusiast for big han|d that the human who are conscience of t\n",
      "Epoch 3. Time: 22.989, Train loss: 1.266\n",
      "ns and peoples must not be estimated by |in recourse to most used involved abits \n",
      "Epoch 4. Time: 22.614, Train loss: 1.256\n",
      "ation but in so far as it is based on be|trouthess brought the generally nay and \n",
      "Epoch 5. Time: 23.213, Train loss: 1.245\n",
      " rather do others afford the high strung| sets he will do causes certain the init\n",
      "Epoch 6. Time: 22.711, Train loss: 1.236\n",
      "ith perfect honesty on the subject of th|eir most enchame as it is they partice i\n",
      "Epoch 7. Time: 21.736, Train loss: 1.227\n",
      " the profoundest antagonism and the nece|ssity compassible are reto it for the ru\n",
      "Epoch 8. Time: 23.519, Train loss: 1.219\n",
      "iment itself but only against its danger|ous and ejececterious life despie and fu\n",
      "Epoch 9. Time: 24.550, Train loss: 1.211\n",
      "traint under which every language has at|avasm of those be ascenness there foundi\n",
      "Epoch 10. Time: 22.882, Train loss: 1.204\n",
      "nfusingly similar to a res ficta et pict|ly confieration what most recurration of\n",
      "Epoch 11. Time: 23.072, Train loss: 1.196\n",
      "orld as thing in itself but the world as| is a right themselves what yet stricked\n",
      "Epoch 12. Time: 24.534, Train loss: 1.191\n",
      "elves precisely here we are men of duty |greatest are rightly worlded than is fre\n",
      "Epoch 13. Time: 22.562, Train loss: 1.184\n",
      "ssary for greatness of soul the wicked s|o that though to them in above all prion\n",
      "Epoch 14. Time: 22.093, Train loss: 1.179\n",
      "rwise with the second type of morality s|ingle being must be worlded for die who \n",
      "Epoch 15. Time: 24.172, Train loss: 1.173\n",
      "ur grandfathers in esteem and also at a |constance love of impulsion the renigian\n",
      "Epoch 16. Time: 22.918, Train loss: 1.166\n",
      " he is free from the crowd the many the |time ones in homitates of how to them go\n",
      "Epoch 17. Time: 24.053, Train loss: 1.162\n",
      "in which religious life flourished most |drafted by the ideas and fair to the nam\n",
      "Epoch 18. Time: 22.454, Train loss: 1.156\n",
      "he theologians whose existence and possi|ble noble to mestmul stupidity in this w\n",
      "Epoch 19. Time: 23.260, Train loss: 1.153\n",
      " been with schumann german music was thr|eabich out of the most developed therefo\n",
      "Epoch 20. Time: 22.683, Train loss: 1.149\n",
      "the whole domain of means through which |special into dreplity now man awave atal\n",
      "Epoch 21. Time: 22.859, Train loss: 1.144\n",
      "ng the word in its higher significance i|tself a ruis all erredity do like eyes p\n",
      "Epoch 22. Time: 21.507, Train loss: 1.140\n",
      "generation we all know something thereof|lient must lack it is storwishment as al\n",
      "Epoch 23. Time: 22.650, Train loss: 1.137\n",
      "nd should finally put that terrible and |unconsti where the rest of case possion \n",
      "Epoch 24. Time: 24.159, Train loss: 1.131\n",
      "d with love even with infatuation and pr|ecisely there is conshercass nor belief \n",
      "Epoch 25. Time: 22.038, Train loss: 1.128\n",
      "le the spectacle of the tartuffery of ol|d manoment of mankind every lencent thei\n",
      "Epoch 26. Time: 23.046, Train loss: 1.124\n",
      "come interesting but let us not be afrai|ds but what refined funders of destrusin\n",
      "Epoch 27. Time: 23.961, Train loss: 1.121\n",
      "timent was frequently transferred to oth|ers the content moral awaking sense but \n",
      "Epoch 28. Time: 22.242, Train loss: 1.118\n",
      "es supposing in effect that man is not j|ust thus looks all in that everything fu\n",
      "Epoch 29. Time: 22.881, Train loss: 1.114\n",
      "th that which was and is but wishes to h|ave refumentance to comes then according\n",
      "Epoch 30. Time: 25.337, Train loss: 1.111\n",
      "ion endorses and strengthens my belief i|n the god the crue to instincts are type\n",
      "Epoch 31. Time: 24.045, Train loss: 1.109\n",
      " which teaches to hate the laisser aller| vent and moralists of an which there ar\n",
      "Epoch 32. Time: 23.003, Train loss: 1.105\n",
      " although from some other motive will be| creations have attained at the browny w\n",
      "Epoch 33. Time: 24.095, Train loss: 1.102\n",
      "ctivity for which one must suppose a sub|ject rover as they write to the fact the\n",
      "Epoch 34. Time: 24.770, Train loss: 1.100\n",
      "e been more interesting to men and even |not accounterness but the restly the day\n",
      "Epoch 35. Time: 23.243, Train loss: 1.095\n",
      "rs who maintain that it has fallen that |fasisian such despetation and stord flee\n",
      "Epoch 36. Time: 23.582, Train loss: 1.094\n",
      "universal primordial law of the apprehen|dent to metaphysical some divine empitat\n",
      "Epoch 37. Time: 23.160, Train loss: 1.091\n",
      "d gradations when they lose moral feelin|g eold be bind the original in its moral\n",
      "Epoch 38. Time: 24.196, Train loss: 1.089\n",
      "he masters of greek philosophy and the b|asi devitably something this is for eura\n",
      "Epoch 39. Time: 22.423, Train loss: 1.087\n",
      "ften ascribes the wrong motives to his a|ntiman do or religion when of voluntario\n",
      "Epoch 40. Time: 23.040, Train loss: 1.084\n",
      "suffering and to be of service in misfor|tunates wherever that your reasome that \n",
      "Epoch 41. Time: 21.306, Train loss: 1.081\n",
      "ty for everything most abhorred is close|ring itself oned more fortuned and decei\n",
      "Epoch 42. Time: 24.257, Train loss: 1.081\n",
      "in my breast says an old scandinavian sa|crificially he have doubtly exist the mo\n",
      "Epoch 43. Time: 23.683, Train loss: 1.078\n",
      " the souls of those few but the clouds a| play and philosophy all to are already \n",
      "Epoch 44. Time: 20.917, Train loss: 1.075\n",
      "litical organization but as equivalent t|ime us not verval preservold into an imp\n",
      "Epoch 45. Time: 22.278, Train loss: 1.073\n",
      " any thing sache to ourselves perhaps it| wimall of the qualities of an ideal of \n",
      "Epoch 46. Time: 24.256, Train loss: 1.071\n",
      "ity of the english populace in which sha|rbitiment of the free spicity as what kn\n",
      "Epoch 47. Time: 23.140, Train loss: 1.069\n",
      " of an action lies precisely in that whi|ch he terrind an is not equality itself \n",
      "Epoch 48. Time: 25.212, Train loss: 1.066\n",
      "he german soul is above all manifold var|ious fessing is meliedes of near of skep\n",
      "Epoch 49. Time: 24.472, Train loss: 1.066\n",
      "ir own dung hill cynicism is the only fo|r termines is more rule of the healing f\n",
      "Epoch 50. Time: 23.660, Train loss: 1.063\n",
      "be asked why it is more honorable in an |invertain mat portion of noble human imm\n",
      "Epoch 51. Time: 24.724, Train loss: 1.062\n",
      "e spoken word arcubalista into armbrust |of constant should at cunashm for their \n",
      "Epoch 52. Time: 24.028, Train loss: 1.062\n",
      "tly and fragile to conceal would roll th|e scation of rule only end an idea for t\n",
      "Epoch 53. Time: 24.043, Train loss: 1.059\n",
      "the most world approving exuberant and v|aluate clearing and hearn to particuls o\n",
      "Epoch 54. Time: 23.599, Train loss: 1.059\n",
      "l systems just as the way seems barred a|pplical christian witk perbeecedes inasm\n",
      "Epoch 55. Time: 23.761, Train loss: 1.055\n",
      "ose burnt children the born artists who |indurchable is they shind and appreholdi\n",
      "Epoch 56. Time: 23.819, Train loss: 1.054\n",
      "ch every thinking mind will strive to ov|ermaffle a suspecting through disparty a\n",
      "Epoch 57. Time: 23.208, Train loss: 1.054\n",
      "ery act of teasing shows what pleasure i|t my vict there are or all opposed by wo\n",
      "Epoch 58. Time: 22.899, Train loss: 1.054\n",
      "carry your point ye know that hitherto n|ecessity or completeness all the long bu\n",
      "Epoch 59. Time: 22.847, Train loss: 1.051\n",
      " general utility and are only so far ent|it of artistic boundly not esception and\n",
      "Epoch 60. Time: 22.111, Train loss: 1.050\n",
      "obable that men on this point will be in|exolaters that it is in i must best such\n",
      "Epoch 61. Time: 22.520, Train loss: 1.047\n",
      "hat we may not be torn to pieces without| fair that not the guilbried with attemp\n",
      "Epoch 62. Time: 22.624, Train loss: 1.046\n",
      "e one s existence within them but this i|ts hithert to havounges to the prejudice\n",
      "Epoch 63. Time: 24.072, Train loss: 1.046\n",
      "d fine neutrality of your conscience it |slowledy their test the imit forselution\n",
      "Epoch 64. Time: 24.742, Train loss: 1.045\n",
      "shion and at the expense of all serious |fiction for interroral pain ye knowish a\n",
      "Epoch 65. Time: 24.502, Train loss: 1.044\n",
      "bastone sacchetti nov to seduce their ne|cessary the devises them short for all i\n",
      "Epoch 66. Time: 23.933, Train loss: 1.042\n",
      "ds and here only is he unrefined and neg|less when they can maid the great name m\n",
      "Epoch 67. Time: 22.681, Train loss: 1.041\n",
      "over like all estimates is continually d|id ask no realize the subjection but all\n",
      "Epoch 68. Time: 23.702, Train loss: 1.041\n",
      "r men who had first to teach their centu|re is englong the animal to physible sen\n",
      "Epoch 69. Time: 23.409, Train loss: 1.039\n",
      " music and philosophy in which the leani|ng of the earfling the hich inclines fea\n",
      "Epoch 70. Time: 23.723, Train loss: 1.038\n",
      "things possessed of color skin and seemi|ng of render and greates which have ther\n",
      "Epoch 71. Time: 23.102, Train loss: 1.038\n",
      "dream but when it opens its eyes it find| unegliance they can blesiate for people\n",
      "Epoch 72. Time: 25.114, Train loss: 1.038\n",
      "enomena alluded to man is conscious of c|onscience made plings to antiorations of\n",
      "Epoch 73. Time: 23.201, Train loss: 1.037\n",
      "ral egoism must be justified too pain is| generally have been a time consensess t\n",
      "Epoch 74. Time: 25.092, Train loss: 1.034\n",
      " and never comes out of his own personal| i mementans and unness to the same time\n",
      "Epoch 75. Time: 23.316, Train loss: 1.033\n",
      "omed not to furnish matter for scientifi|cated it way again belongs to much manit\n",
      "Epoch 76. Time: 22.327, Train loss: 1.034\n",
      "s it although in fact it is the stronges|t called your most self even in short sh\n",
      "Epoch 77. Time: 23.008, Train loss: 1.033\n",
      "in which is betrayed the sense of victor| the neight in the refined fewstrifional\n",
      "Epoch 78. Time: 23.634, Train loss: 1.031\n",
      "f servitude and bondage which the positi|on to naturals and responsible enduring \n",
      "Epoch 79. Time: 25.818, Train loss: 1.029\n",
      "confusion and mutual misunderstanding of| the skeptics of christory of mandorman \n",
      "Epoch 80. Time: 23.560, Train loss: 1.031\n",
      "intained in europe is perhaps the best e|dulance to the world of life begins of n\n",
      "Epoch 81. Time: 23.201, Train loss: 1.029\n",
      "s and religions we are prepared as no ot|hers occride that i believe by accounta \n",
      "Epoch 82. Time: 24.144, Train loss: 1.030\n",
      " as yet belong to the domain of moral va|nical now neighle seems to one involunta\n",
      "Epoch 83. Time: 24.429, Train loss: 1.029\n",
      " the highest utility must be ascribed th|e unconquerate into nevertheless as ince\n",
      "Epoch 84. Time: 22.588, Train loss: 1.029\n",
      " for the bible has hitherto been maintai|ned further rule only the hands to end t\n",
      "Epoch 85. Time: 21.322, Train loss: 1.026\n",
      "w attain to moral honour the gregarious |and science under again has been utifita\n",
      "Epoch 86. Time: 23.644, Train loss: 1.029\n",
      "eption than myself the exception and he |caer of the this accession in sinful of \n",
      "Epoch 87. Time: 23.222, Train loss: 1.025\n",
      "the commanding and the obeying parties a|nd spirit shudder to explained against w\n",
      "Epoch 88. Time: 22.925, Train loss: 1.025\n",
      "us thing of which a scholar is capable r|ights as one uttance with the refuce one\n",
      "Epoch 89. Time: 23.034, Train loss: 1.028\n",
      " more joyfully any more than it was the |dogoration is perhaps securd as protecti\n",
      "Epoch 90. Time: 23.908, Train loss: 1.024\n",
      "many things and enjoins upon them other |whole faith glances and in simile for us\n",
      "Epoch 91. Time: 22.922, Train loss: 1.024\n",
      "teps upon which his servants the scienti|fic sprinss changer not as is nothing qu\n",
      "Epoch 92. Time: 24.951, Train loss: 1.022\n",
      "opposing scorn and contempt to the ambit|ives one who have entire done may do the\n",
      "Epoch 93. Time: 23.046, Train loss: 1.024\n",
      "not sufficiently noble to see the radica|l opposite the self delusions dreams no \n",
      "Epoch 94. Time: 22.610, Train loss: 1.022\n",
      "o a religious interpretation of existenc|e as loved not only a permitival upon as\n",
      "Epoch 95. Time: 24.259, Train loss: 1.023\n",
      "ination capacity and morality in the hea|rt that it were goodness is it with all \n",
      "Epoch 96. Time: 23.963, Train loss: 1.023\n",
      "est served thereby they would like by al|l must hauts they almost will conception\n"
     ]
    }
   ],
   "source": [
    "for ep in range(100):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_b, y_b in data:\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        answers = model(X_b)\n",
    "        loss = criterion(answers, y_b)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "    model.eval()\n",
    "    generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzUTHB9O_H6J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Занятие 6. Рекуррентные сети 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
